---
title: "Processing Fastq to Bam"
author: "Briana Mittleman"
date: "4/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


The raw data in this analysis are fastq files for each of the libraries. The fastq files are in apaQTL/data/fastq/. The goal of this analysis is to process the fastq files into bam files with alligned and clean data. The major filtering steps in this process are removing reads with evidence of mapping bias due to allele specific effects and removing reads with evidence for misprimming. All of the steps for this analyis are completed through a snakemake pipeline. The necessary files to run the pipeline are in apaQTL/code/. 

The snakemake pipeline can be run on a paralell set of data by changing the working directory in the config.yaml file. The environment for this analysis is creating using anaconda with the environemnt file apaQTL/code/environment.yaml. 


Before running the pipeline it is usefull to load the environment and create a dag for all of the commands that will be run. This will allow me to make sure there are no syntax errors or path errors preventing the full pipeline from running. 

```{bash,eval=F}
module load Anaconda3
source activate three-prime-env
snakemake -np 
```


To run the pipeline I submit the snakemake.batch script. This will run submit-snakemake.sh and submit a job for each rule. All of the log files will be in apaQTL/code/log/

```{bash,eval=F}
sbatch snakemake.batch  
```


All of the files created from this pipeline will be in apaQTL/data/. The final clean and filtered bam files that are ready for peak calling and further analysis are in apaQTL/data/sort_clean/.


